from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import time
import pandas as pd
import random

# âœ… í¬ë¡¬ ì˜µì…˜ ì„¤ì •
chrome_options = Options()
chrome_options.add_argument("--headless")  # ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰
chrome_options.add_argument("--disable-blink-features=AutomationControlled")  # ìë™í™” ê°ì§€ ë°©ì§€
chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
chrome_options.add_experimental_option("detach", True)

# âœ… ì›¹ë“œë¼ì´ë²„ ì‹¤í–‰
driver = webdriver.Chrome(options=chrome_options)
driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")  # WebDriver íƒì§€ ìš°íšŒ
driver.implicitly_wait(5)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
driver.set_window_size(1920, 1080)  # ì°½ í¬ê¸° ì„¤ì •

# âœ… í¬ë¡¤ë§í•  URL (ë„¤ì´ë²„ ë¸Œëœë“œ í˜ì´ì§€)
page_url = "https://brand.naver.com/cetaphilshop/products/11528152893#REVIEW"
driver.get(page_url)
time.sleep(5)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

# âœ… ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
reviews_data = []

def scrape_reviews():
    """í˜„ì¬ í˜ì´ì§€ì—ì„œ ë¦¬ë·° ë°ì´í„°ë¥¼ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜"""
    review_elements = driver.find_elements(By.CSS_SELECTOR, "div._1CkGh7Rgzq")
    print(f"ğŸ” {len(review_elements)}ê°œì˜ ë¦¬ë·° ê°ì§€ë¨")

    for review in review_elements:
        try:
            # ì‘ì„±ì ì •ë³´
            author = review.find_element(By.CSS_SELECTOR, "strong._3eMaa46Quy").text.strip()

            # ë¦¬ë·° ë‚ ì§œ
            date = review.find_elements(By.CSS_SELECTOR, "span._3eMaa46Quy")[1].text.strip()

            # í‰ì 
            rating = review.find_element(By.CSS_SELECTOR, "em._15NU42F3kT").text.strip()

            # ë¦¬ë·° ë‚´ìš©
            content = review.text 

            # ë¦¬ë·° ì´ë¯¸ì§€ (ì—†ìœ¼ë©´ "ì´ë¯¸ì§€ ì—†ìŒ")
            try:
                image_element = review.find_element(By.CSS_SELECTOR, "img")
                image_url = image_element.get_attribute("src")
            except:
                image_url = "ì´ë¯¸ì§€ ì—†ìŒ"

            # ë°ì´í„° ì €ì¥
            reviews_data.append([author, date, rating, content, image_url])

        except Exception as e:
            print(f"âŒ ë¦¬ë·° í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

# âœ… ì²« ë²ˆì§¸ í˜ì´ì§€ ë¦¬ë·° í¬ë¡¤ë§
print("ğŸš€ ì²« ë²ˆì§¸ í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘...")
scrape_reviews()

# âœ… ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ë° í¬ë¡¤ë§ ì‹¤í–‰ (ìµœëŒ€ 10í˜ì´ì§€)
for i in range(1, 11):  # 2í˜ì´ì§€ë¶€í„° 10í˜ì´ì§€ê¹Œì§€ ì´ë™
    try:
        print(f"ğŸ“¢ {i} í˜ì´ì§€ ì´ë™ ì¤‘...")

        # âœ… í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ê°€ì§„ a íƒœê·¸ í´ë¦­ (í´ë˜ìŠ¤ "UWN4IvaQza"ë¥¼ ì‚¬ìš©)
        next_page_buttons = driver.find_elements(By.CLASS_NAME, "UWN4IvaQza")

        for button in next_page_buttons:
            if button.text == str(i):  # i ë²ˆì§¸ í˜ì´ì§€ ì°¾ê¸°
                driver.execute_script("arguments[0].click();", button)  # JavaScript í´ë¦­
                time.sleep(random.randint(3, 6))  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                break  # í•´ë‹¹ í˜ì´ì§€ë¥¼ ì°¾ìœ¼ë©´ í´ë¦­ í›„ ì¢…ë£Œ

        # âœ… í•´ë‹¹ í˜ì´ì§€ ë¦¬ë·° í¬ë¡¤ë§ ì‹¤í–‰
        scrape_reviews()

    except Exception as e:
        print(f"âš ï¸ {i} í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨: {e}")
        break  # í˜ì´ì§€ ì´ë™ ì‹¤íŒ¨ ì‹œ ë°˜ë³µ ì¤‘ë‹¨

# âœ… í¬ë¡¤ë§ëœ ë°ì´í„° ì €ì¥
df = pd.DataFrame(reviews_data, columns=["ì‘ì„±ì", "ë‚ ì§œ", "í‰ì ", "ë‚´ìš©", "ì´ë¯¸ì§€ URL"])
df.to_csv("naver_reviews.csv", index=False, encoding="utf-8-sig")

print("âœ… í¬ë¡¤ë§ ì™„ë£Œ! ë°ì´í„°ê°€ naver_reviews.csv íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# âœ… ë“œë¼ì´ë²„ ì¢…ë£Œ
driver.quit()
